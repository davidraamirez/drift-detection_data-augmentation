{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Ejemplos/Distribuciones/Binomial-fin.csv',index_col='indice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_periodos(inicio, periodos, freq): \n",
    "    serie = pd.date_range(start=inicio, periods=periodos, freq=freq)\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESPLAZAMIENTO TEMPORAL Y TRASLACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_shift(series, shift):\n",
    "    return series.shift(shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traslacion(df,shift):\n",
    "    df[df.columns[0]] = df[df.columns[0]] + shift\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AGREGAR RUIDO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(series, noise_level=0.1):\n",
    "    noise = np.random.normal(0, noise_level, len(series))\n",
    "    return series + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_ruido(df,noise_level=0.1):\n",
    "    df[df.columns[0]] = add_noise(df[df.columns[0]],noise_level)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ESCALADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(series,factor):\n",
    "    return series*factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_scale(df,factor):\n",
    "    df[df.columns[0]] = scale(df[df.columns[0]],factor)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECORTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(series, start, end):\n",
    "    return series[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recorte(df, start,end):\n",
    "    df[df.columns[0]] = crop(df[df.columns[0]],start,end)\n",
    "    df=df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_cuts(data, n_cuts=5):\n",
    "    cuts = np.random.randint(0, len(data), size=n_cuts)\n",
    "    return data[cuts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_random_cuts(df,freq,n_cuts=5):\n",
    "    data = df[df.columns[0]].values\n",
    "    data_cut = random_cuts(data,n_cuts)\n",
    "    indice=series_periodos(df.index[0],n_cuts,freq)\n",
    "    df_cut=pd.DataFrame(data=data_cut,index=indice,columns=df.columns)\n",
    "    return df_cut\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTERPOLACION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from scipy.interpolate import UnivariateSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolacion(df,kind,num,freq):\n",
    "    df=df.reset_index()\n",
    "    indices=df.index.values\n",
    "    x =indices \n",
    "    print(x)\n",
    "    y = df[df.columns[1]]\n",
    "    print(y)\n",
    "    f = interp1d(x, y, kind=kind) #kind='linear' / 'cubic'\n",
    "    x_new = np.linspace(0, 4, num=num)  # New x values\n",
    "    y_new = f(x_new)  # Interpolated y values\n",
    "    indice=series_periodos(df[df.columns[0]][0],num,freq)\n",
    "    df_int=pd.DataFrame(data=y_new,index=indice)\n",
    "    return df_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(data):\n",
    "    interpolated_data = []\n",
    "    for i in range(len(data) - 1):\n",
    "        interpolated_data.append(data[i])\n",
    "        interpolated_data.append((data[i] + data[i + 1]) / 2)  # Punto intermedio\n",
    "    interpolated_data.append(data[-1])\n",
    "    return np.array(interpolated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punto_medio(df,freq):\n",
    "    data =df[df.columns[0]]\n",
    "    a=interpolate(data)\n",
    "    indice=series_periodos(df.index[0],len(a),freq)\n",
    "    df_pm=pd.DataFrame(data=a,index=indice)\n",
    "    return df_pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spline_interpolation(data, s=1):\n",
    "    x = np.arange(len(data))\n",
    "    spline = UnivariateSpline(x, data, s=s)\n",
    "    return spline(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolacion_spline(df,s):\n",
    "    data = df[df.columns[0]]\n",
    "    df[df.columns[0]]=spline_interpolation(data,s)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM SAMPLING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sampling with replacement\n",
    "def sampling(df,size,freq):\n",
    "    data =df[df.columns[0]]\n",
    "    sampled_data = np.random.choice(data, size=size, replace=True)\n",
    "    indice=series_periodos(df.index[0],size,freq)\n",
    "    df_sampling=pd.DataFrame(data=sampled_data,index=indice,columns=df.columns)\n",
    "    return df_sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRANSFORMACIÓN MATEMÁTICA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_log(df):\n",
    "    data = df[df.columns[0]]\n",
    "    log_transformed_data = np.log1p(data)\n",
    "    df[df.columns[0]] = log_transformed_data\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_sqrt(df):\n",
    "    data = df[df.columns[0]]\n",
    "    df[df.columns[0]] = np.sqrt(data)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_exp(df,factor):\n",
    "    data = df[df.columns[0]]\n",
    "    df[df.columns[0]] = np.exp(data/factor)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_sin(df):\n",
    "    data = df[df.columns[0]]\n",
    "    df[df.columns[0]] = np.sin(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_cos(df):\n",
    "    data = df[df.columns[0]]\n",
    "    df[df.columns[0]] = np.cos(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_trig(df):\n",
    "    data = df[df.columns[0]]\n",
    "    df[df.columns[0]] = np.cos(data) + np.sin(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_sigmoid(df):\n",
    "    data = df[df.columns[0]]\n",
    "    df[df.columns[0]] =1 / (1 + np.exp(-data))\n",
    "    return df\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIXUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(data, alpha=0.2):\n",
    "    lambda_ = np.random.beta(alpha, alpha)\n",
    "    indices = np.random.permutation(len(data))\n",
    "    data_mixup = lambda_ * data + (1 - lambda_) * data[indices]\n",
    "    return data_mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_mixup(df,alpha=0.2):\n",
    "    df[df.columns[0]] = mixup(df[df.columns[0]].values,alpha)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indice</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-31</th>\n",
       "      <td>16.165199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-28</th>\n",
       "      <td>136.623102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-31</th>\n",
       "      <td>18.777608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-30</th>\n",
       "      <td>95.252260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-31</th>\n",
       "      <td>97.385959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-31</th>\n",
       "      <td>13.785253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-30</th>\n",
       "      <td>89.284300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-31</th>\n",
       "      <td>376.298397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-30</th>\n",
       "      <td>86.980632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>270.792916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Valor\n",
       "indice                \n",
       "2014-01-31   16.165199\n",
       "2014-02-28  136.623102\n",
       "2014-03-31   18.777608\n",
       "2014-04-30   95.252260\n",
       "2014-05-31   97.385959\n",
       "...                ...\n",
       "2023-08-31   13.785253\n",
       "2023-09-30   89.284300\n",
       "2023-10-31  376.298397\n",
       "2023-11-30   86.980632\n",
       "2023-12-31  270.792916\n",
       "\n",
       "[120 rows x 1 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agregar_mixup(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mix(data, n_samples=100):\n",
    "    mixed_data = []\n",
    "    for _ in range(n_samples):\n",
    "        i, j = np.random.choice(len(data), 2, replace=False)\n",
    "        mixed_data.append((data[i] + data[j]) / 2)\n",
    "    return np.array(mixed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_random_mix(df,freq,n_samples):\n",
    "    sampled_data = random_mix(df[df.columns[0]],n_samples)\n",
    "    indice=series_periodos(df.index[0],n_samples,freq)\n",
    "    df_sampling=pd.DataFrame(data=sampled_data,index=indice,columns=df.columns)\n",
    "    return df_sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VENTANAS DESLIZANTES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ventanas(df,ventana):\n",
    "    df[df.columns[0]]=df[df.columns[0]].rolling(window=ventana).mean()\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data_multidim = np.array([[1.2, 3.4], [5.6, 7.8], [9.1, 2.2]])\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(data_multidim)\n",
    "data_pca_jittered = data_pca + np.random.normal(0, 0.1, data_pca.shape)\n",
    "data_augmented = pca.inverse_transform(data_pca_jittered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USO DE TECNICAS ESTADÍSTICAS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal(df,freq,size):\n",
    "    data = df[df.columns[0]]\n",
    "    mean,std_dev=np.mean(data),np.std(data)\n",
    "    data_augmented = np.random.normal(mean,std_dev,size=data.shape)\n",
    "    indice=series_periodos(df.index[0],size,freq)\n",
    "    df_tf=pd.DataFrame(data=data_augmented,index=indice,columns=df.columns)\n",
    "    return df_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal(df,freq,sigma,size):\n",
    "    data = df[df.columns[0]].values\n",
    "    data_augmented = np.random.lognormal(mean=np.log(data.mean()),sigma=sigma,size=size)\n",
    "    indice=series_periodos(df.index[0],size,freq)\n",
    "    df_tf=pd.DataFrame(data=data_augmented,index=indice,columns=df.columns)\n",
    "    return df_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_muller_transform(mean, std_dev, size=100):\n",
    "    u1, u2 = np.random.rand(size), np.random.rand(size)\n",
    "    z1 = np.sqrt(-2 * np.log(u1)) * np.cos(2 * np.pi * u2)\n",
    "    return mean + z1 * std_dev\n",
    "\n",
    "def box_muller(df,freq,size):\n",
    "    data = df[df.columns[0]].values\n",
    "    data_tf=box_muller_transform(data.mean(),data.std(),size)\n",
    "    indice=series_periodos(df.index[0],size,freq)\n",
    "    df_tf=pd.DataFrame(data=data_tf,index=indice,columns=df.columns)\n",
    "    return df_tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESPLAZAMIENTO EN BLOQUES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def despl_bloque(df,block_size):\n",
    "    data = df[df.columns[0]].values\n",
    "    shifted_data = []\n",
    "    for i in range(0,len(data),block_size):\n",
    "        block = data[i:i+block_size]\n",
    "        shifted_block = np.roll(block, np.random.randint(1, block_size))\n",
    "        shifted_data.extend(shifted_block)\n",
    "    df[df.columns[0]]=np.array(shifted_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROTACIÓN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotacion(df):\n",
    "    data = df[df.columns[0]].values\n",
    "    rotation_steps = np.random.randint(1, len(data))\n",
    "    df[df.columns[0]]= np.roll(data, rotation_steps)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUIDO ARMONICO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_harmonic_noise(df, amplitude=0.1, frequency=0.5):\n",
    "    data = df[df.columns[0]].values\n",
    "    time = np.arange(len(data))\n",
    "    harmonic_noise = amplitude * np.sin(2 * np.pi * frequency * time)\n",
    "    df[df.columns[0]] = data + harmonic_noise\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOOTSTRAPPING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_bootstrapping(df,freq):\n",
    "    # Suponiendo  que df es tu DataFrame con series temporales originales\n",
    "    synthetic_data = df.sample(frac=1, replace=True).reset_index(drop=True)\n",
    "    synthetic_data['Valor'] += np.random.normal(0, 0.1, len(synthetic_data))  # Añadir ruido\n",
    "    indice=series_periodos(df.index[0],len(df)+len(synthetic_data),freq)\n",
    "    a=pd.concat([df['Valor'],synthetic_data['Valor']])\n",
    "    a.index=indice\n",
    "    df_bootstrap=pd.DataFrame(data=a)\n",
    "    return df_bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERTURBACIÓN GAUSSIANA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_gaussian_perturbation(data, std_dev=0.05):\n",
    "    perturbations = np.random.normal(0, std_dev, len(data))\n",
    "    cumulative_data = np.cumsum(perturbations) + data\n",
    "    return cumulative_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregacion_gauss(df,std_dev=0.05):\n",
    "    df[df.columns[0]] = cumulative_gaussian_perturbation(df[df.columns[0]],std_dev)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRANSFORMACIÓN WAVELET:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_transform_augmentation(data, wavelet='db1'):\n",
    "    coeffs = pywt.wavedec(data, wavelet)\n",
    "    coeffs[0] += np.random.normal(0, 0.1, len(coeffs[0]))  # Añadir ruido al coeficiente principal\n",
    "    augmented_data = pywt.waverec(coeffs, wavelet)\n",
    "    return augmented_data[:len(data)]  # Para mantener el tamaño original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_wavelet(df,wavelet='db1'):\n",
    "    data = df[df.columns[0]].values\n",
    "    data_tf=wavelet_transform_augmentation(data,wavelet)\n",
    "    df[df.columns[0]] = data_tf\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DUPLICADO + PERTURBACIÓN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_and_perturb(data, duplication_factor=0.3, perturbation_std=0.05):\n",
    "    duplicated_data = []\n",
    "    for point in data:\n",
    "        duplicated_data.append(point)\n",
    "        if np.random.rand() < duplication_factor:\n",
    "            duplicated_data.append(point + np.random.normal(0, perturbation_std))\n",
    "    return np.array(duplicated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicados(df,freq,duplication_factor=0.3,perturbation_std=0.05):\n",
    "    data = df[df.columns[0]]\n",
    "    data_dd=duplicate_and_perturb(data,duplication_factor,perturbation_std)\n",
    "    indice=series_periodos(df.index[0],len(data_dd),freq)\n",
    "    df_dd=pd.DataFrame(data=data_dd,index=indice,columns=df.columns)\n",
    "    return df_dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIMULACIÓN DE SALTOS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pulse_noise(data, num_pulses=5, amplitude=1):\n",
    "    pulse_indices = np.random.choice(len(data), num_pulses, replace=False)\n",
    "    pulse_data = data.copy()\n",
    "    for i in pulse_indices:\n",
    "        pulse_data[i] += np.random.uniform(-amplitude, amplitude)\n",
    "    return pulse_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_saltos(df,num_pulses=5,amplitude=1):\n",
    "    data = df [df.columns[0]]\n",
    "    data_salto=pulse_noise(data,num_pulses,amplitude)\n",
    "    df[df.columns[0]]= data_salto\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMBINACIÓN LINEAL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_combinations(data, n_combinations):\n",
    "    combinations = []\n",
    "    for _ in range(n_combinations):\n",
    "        weights = np.random.rand(data.shape[0])\n",
    "        weights /= np.sum(weights)  # Normalizar pesos\n",
    "        combination = np.dot(weights, data)\n",
    "        combinations.append(combination)\n",
    "    return np.array(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_comb(df,freq,size):\n",
    "    data = df[df.columns[0]]\n",
    "    data_augmented = linear_combinations(data,size)\n",
    "    datos=np.concatenate((data.values,data_augmented))\n",
    "    indice=series_periodos(df.index[0],len(datos),freq)\n",
    "    df_dl=pd.DataFrame(data=datos,index=indice,columns=df.columns)\n",
    "    return df_dl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
